{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_project_ViT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WrLbr5s4Lrw",
        "outputId": "315f7232-f7a8-44d8-fde1-e5143a810047"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0jLHgQB4b8h",
        "outputId": "7a36bf55-0919-4f9f-9d1b-72833abdd877"
      },
      "source": [
        "!cp -av 'drive/MyDrive/CV/final_project/data_pure.zip' './' \n",
        "!unzip -u -q \"data_pure.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'drive/MyDrive/CV/final_project/data_pure.zip' -> './data_pure.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCoNDp5z4kiZ",
        "outputId": "b50a9388-f1d0-4768-9973-04006c715721"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "\n",
        "seed = 1\n",
        "base_dir = './'\n",
        "image_size=224\n",
        "\n",
        "df = pd.read_csv(base_dir+\"data/train.csv\")\n",
        "df['filename'] = df.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "\n",
        "def prep_fn(img):\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    #img = (img - 0.5) * 2\n",
        "    return img\n",
        "\n",
        "data_gen_args = dict(preprocessing_function=prep_fn,\n",
        "                     width_shift_range=0.2,\n",
        "                     height_shift_range=0.2,\n",
        "                     zoom_range=0.1,\n",
        "                     rotation_range=20,\n",
        "                     horizontal_flip=False,\n",
        "                     vertical_flip=False,\n",
        "                     validation_split=0.1)\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=prep_fn,validation_split=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                    directory=base_dir+'data/train/',\n",
        "                                                    x_col='filename',\n",
        "                                                    y_col=['x','y'],\n",
        "                                                    subset=\"training\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    seed=seed,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='raw',\n",
        "                                                    target_size=(image_size,image_size))\n",
        "val_generator = val_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                directory=base_dir+'data/train/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                subset=\"validation\",\n",
        "                                                batch_size = 32,\n",
        "                                                seed=seed,\n",
        "                                                shuffle=True,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(image_size,image_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6750 validated image filenames.\n",
            "Found 750 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9-Aflf04tOz",
        "outputId": "8793ad6a-bf15-4463-b5fe-5c21c48fdd62"
      },
      "source": [
        "df_test = pd.read_csv(\"data/imagenames.csv\")\n",
        "df_test['filename'] = df_test.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "df_test['x']=0\n",
        "df_test['y']=0\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n",
        "                                                directory=base_dir+'data/test/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                batch_size = 32,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHr19WqT7Ot9"
      },
      "source": [
        "patch_size=14\n",
        "num_patches = (image_size//patch_size) **2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [projection_dim*2, projection_dim]\n",
        "transformer_layers = 5\n",
        "#mlp_head_units = [256,128,64]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E32sxgO7s0P"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = L.Dense(units, activation = tf.nn.gelu)(x)\n",
        "        x = L.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWXII9bq8r1O"
      },
      "source": [
        "class Patches(L.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images = images,\n",
        "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
        "            strides = [1, self.patch_size, self.patch_size, 1],\n",
        "            rates = [1, 1, 1, 1],\n",
        "            padding = 'VALID',\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        # batch_size, n_batches, patch_flattened\n",
        "        return patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqOq-zvNKZ3x"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2VqMWU9bL-"
      },
      "source": [
        "class PatchEncoder(L.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        #self.projection = L.Conv2D(projection_dim,(patch_size,patch_size))\n",
        "        self.projection = L.Dense(units = projection_dim)\n",
        "        self.position_embedding = L.Embedding(\n",
        "            input_dim = num_patches, output_dim = projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fVQxBjF_Ail"
      },
      "source": [
        "def convolution_block(img_input):\n",
        "    x = L.Conv2D(32, (5, 5), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = L.Conv2D(32, (5, 5), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = L.MaxPooling2D((3, 3), strides=(3, 3), name='block1_pool')(x)\n",
        "    \n",
        "    x = L.Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = L.Conv2D(64, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = L.MaxPooling2D((3, 3), strides=(3, 3), name='block2pool')(x)\n",
        "    \n",
        "    x = L.Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = L.Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = L.MaxPooling2D((3, 3), strides=(3, 3), name='block3_pool')(x)\n",
        "    \n",
        "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = L.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "    \n",
        "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = L.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    x = L.Flatten()(x)\n",
        "    x = L.Dense(512,activation='relu')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBC3I7MG-eyC"
      },
      "source": [
        "def vision_transformer():\n",
        "    inputs = L.Input(shape = (image_size, image_size, 3))\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(inputs)\n",
        "    #conv_features= convolution_block(inputs)\n",
        "\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        \n",
        "        # Layer normalization 1.\n",
        "        x1 = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "        \n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = L.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = projection_dim, dropout = 0.1\n",
        "        )(x1, x1)\n",
        "        \n",
        "        # Skip connection 1.\n",
        "        x2 = L.Add()([attention_output, encoded_patches])\n",
        "        \n",
        "        # Layer normalization 2.\n",
        "        x3 = L.LayerNormalization(epsilon = 1e-6)(x2)\n",
        "        \n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0.1)\n",
        "        \n",
        "        # Skip connection 2.\n",
        "        encoded_patches = L.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "    #print(representation[:,0,:].shape)\n",
        "    representation = representation[:,0,:]\n",
        "    #representation = L.Flatten()(representation)\n",
        "    #representation = L.Dropout(0)(representation)\n",
        "    \n",
        "\n",
        "    # Add MLP.\n",
        "    vit_features = L.Dense(128,activation='relu')(representation)\n",
        "    #x = L.Concatenate(axis=1)([vit_features, conv_features])\n",
        "    #x = L.Dense(256,activation='relu')(vit_features)\n",
        "    #x = L.Dense(128,activation='relu')(x)\n",
        "    # Classify outputs.\n",
        "    out = L.Dense(2)(vit_features)\n",
        "    \n",
        "    # Create the model.\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAlaJpP9-yWH"
      },
      "source": [
        "model = vision_transformer()\n",
        "model.compile(optimizer = Adam(learning_rate=0.001), \n",
        "              loss=MeanAbsoluteError())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72lUv-ihDAjE",
        "outputId": "a31d4579-9b93-47a3-db4a-a5a87b9d429d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "patches_22 (Patches)            (None, None, 588)    0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "patch_encoder_20 (PatchEncoder) (None, 256, 256)     216320      patches_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_204 (LayerN (None, 256, 256)     512         patch_encoder_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_92 (MultiH (None, 256, 256)     1051904     layer_normalization_204[0][0]    \n",
            "                                                                 layer_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_184 (Add)                   (None, 256, 256)     0           multi_head_attention_92[0][0]    \n",
            "                                                                 patch_encoder_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_205 (LayerN (None, 256, 256)     512         add_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_266 (Dense)               (None, 256, 512)     131584      layer_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_203 (Dropout)           (None, 256, 512)     0           dense_266[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_267 (Dense)               (None, 256, 256)     131328      dropout_203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_204 (Dropout)           (None, 256, 256)     0           dense_267[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_185 (Add)                   (None, 256, 256)     0           dropout_204[0][0]                \n",
            "                                                                 add_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_206 (LayerN (None, 256, 256)     512         add_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_93 (MultiH (None, 256, 256)     1051904     layer_normalization_206[0][0]    \n",
            "                                                                 layer_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_186 (Add)                   (None, 256, 256)     0           multi_head_attention_93[0][0]    \n",
            "                                                                 add_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_207 (LayerN (None, 256, 256)     512         add_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_268 (Dense)               (None, 256, 512)     131584      layer_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_205 (Dropout)           (None, 256, 512)     0           dense_268[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_269 (Dense)               (None, 256, 256)     131328      dropout_205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_206 (Dropout)           (None, 256, 256)     0           dense_269[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_187 (Add)                   (None, 256, 256)     0           dropout_206[0][0]                \n",
            "                                                                 add_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_208 (LayerN (None, 256, 256)     512         add_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_94 (MultiH (None, 256, 256)     1051904     layer_normalization_208[0][0]    \n",
            "                                                                 layer_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_188 (Add)                   (None, 256, 256)     0           multi_head_attention_94[0][0]    \n",
            "                                                                 add_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_209 (LayerN (None, 256, 256)     512         add_188[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_270 (Dense)               (None, 256, 512)     131584      layer_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_207 (Dropout)           (None, 256, 512)     0           dense_270[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_271 (Dense)               (None, 256, 256)     131328      dropout_207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_208 (Dropout)           (None, 256, 256)     0           dense_271[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_189 (Add)                   (None, 256, 256)     0           dropout_208[0][0]                \n",
            "                                                                 add_188[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_210 (LayerN (None, 256, 256)     512         add_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_95 (MultiH (None, 256, 256)     1051904     layer_normalization_210[0][0]    \n",
            "                                                                 layer_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_190 (Add)                   (None, 256, 256)     0           multi_head_attention_95[0][0]    \n",
            "                                                                 add_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_211 (LayerN (None, 256, 256)     512         add_190[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_272 (Dense)               (None, 256, 512)     131584      layer_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_209 (Dropout)           (None, 256, 512)     0           dense_272[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_273 (Dense)               (None, 256, 256)     131328      dropout_209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_210 (Dropout)           (None, 256, 256)     0           dense_273[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_191 (Add)                   (None, 256, 256)     0           dropout_210[0][0]                \n",
            "                                                                 add_190[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_212 (LayerN (None, 256, 256)     512         add_191[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_96 (MultiH (None, 256, 256)     1051904     layer_normalization_212[0][0]    \n",
            "                                                                 layer_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_192 (Add)                   (None, 256, 256)     0           multi_head_attention_96[0][0]    \n",
            "                                                                 add_191[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_213 (LayerN (None, 256, 256)     512         add_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_274 (Dense)               (None, 256, 512)     131584      layer_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_211 (Dropout)           (None, 256, 512)     0           dense_274[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_275 (Dense)               (None, 256, 256)     131328      dropout_211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_212 (Dropout)           (None, 256, 256)     0           dense_275[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_193 (Add)                   (None, 256, 256)     0           dropout_212[0][0]                \n",
            "                                                                 add_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_214 (LayerN (None, 256, 256)     512         add_193[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_12 (Sl (None, 256)          0           layer_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_276 (Dense)               (None, 32)           8224        tf.__operators__.getitem_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_277 (Dense)               (None, 2)            66          dense_276[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,804,322\n",
            "Trainable params: 6,804,322\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLzW1hjV_Dp2",
        "outputId": "552225ba-6116-4597-f356-352dbbd0ac2c"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    #model.load_weights(\"drive/MyDrive/CV/Model/vit\")\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    r=model.fit(train_generator, validation_data=val_generator,\n",
        "                validation_steps=20,steps_per_epoch=211,epochs=100,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "211/211 [==============================] - 102s 483ms/step - loss: 15.0773 - val_loss: 17.0121\n",
            "Epoch 2/100\n",
            "211/211 [==============================] - 101s 479ms/step - loss: 14.9293 - val_loss: 15.2421\n",
            "Epoch 3/100\n",
            "211/211 [==============================] - 101s 478ms/step - loss: 14.7058 - val_loss: 16.3579\n",
            "Epoch 4/100\n",
            "211/211 [==============================] - 101s 481ms/step - loss: 14.5648 - val_loss: 16.9443\n",
            "Epoch 5/100\n",
            "211/211 [==============================] - 102s 484ms/step - loss: 14.6368 - val_loss: 15.7905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtIzp0sjSoXB"
      },
      "source": [
        "model.save_weights(\"drive/MyDrive/CV/Model/vit\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5o3xrPGR4dO",
        "outputId": "b163853e-5fd3-4411-d020-af6b54e9b40e"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    ypred = model.predict(test_generator)\n",
        "ypred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIe_mDePaBMx"
      },
      "source": [
        "df_test['x'] = ypred[:,0]\n",
        "df_test['y'] = ypred[:,1]\n",
        "if 'filename' in df_test.keys():\n",
        "    df_test=df_test.drop(columns=['filename'])\n",
        "df_test.head()\n",
        "df_test.to_csv('pred_vit.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
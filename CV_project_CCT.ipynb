{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_project_CCT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGgZzpDLsqOZ",
        "outputId": "388fff19-5953-4ec7-ea5b-309dc31dfe93"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36_-LhAXu3AT",
        "outputId": "c7045b6e-1450-45dc-89c9-f3c734acefd3"
      },
      "source": [
        "!cp -av 'drive/MyDrive/CV/final_project/data_pure.zip' './' \n",
        "!unzip -u -q \"data_pure.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'drive/MyDrive/CV/final_project/data_pure.zip' -> './data_pure.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsIjWYHiu5zu",
        "outputId": "60409f6c-72ab-4000-ee1d-690f55b9e874"
      },
      "source": [
        "!pip install -U -q tensorflow-addons"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 41.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 14.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi1sad5XvAup",
        "outputId": "b9b67316-739a-4793-afd0-7b5e53bbf76f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "seed = 1\n",
        "base_dir = './'\n",
        "image_size=224\n",
        "\n",
        "df = pd.read_csv(base_dir+\"data/train.csv\")\n",
        "df['filename'] = df.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "\n",
        "def prep_fn(img):\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    #img = (img - 0.5) * 2\n",
        "    return img\n",
        "\n",
        "data_gen_args = dict(preprocessing_function=prep_fn,\n",
        "                     width_shift_range=0.2,\n",
        "                     height_shift_range=0.2,\n",
        "                     zoom_range=0.1,\n",
        "                     rotation_range=20,\n",
        "                     horizontal_flip=False,\n",
        "                     vertical_flip=False,\n",
        "                     validation_split=0.1)\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=prep_fn,validation_split=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                    directory=base_dir+'data/train/',\n",
        "                                                    x_col='filename',\n",
        "                                                    y_col=['x','y'],\n",
        "                                                    subset=\"training\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    seed=seed,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='raw',\n",
        "                                                    target_size=(224,224))\n",
        "val_generator = val_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                directory=base_dir+'data/train/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                subset=\"validation\",\n",
        "                                                batch_size = 32,\n",
        "                                                seed=seed,\n",
        "                                                shuffle=True,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(224,224))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6750 validated image filenames.\n",
            "Found 750 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az3c9Aq5lmqv",
        "outputId": "362e6800-3651-4643-a9b9-b0e2a5dbf6e5"
      },
      "source": [
        "df_test = pd.read_csv(\"data/imagenames.csv\")\n",
        "df_test['filename'] = df_test.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "df_test['x']=0\n",
        "df_test['y']=0\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n",
        "                                                directory=base_dir+'data/test/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                batch_size = 32,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(224,224))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE4zHMGrvSvm"
      },
      "source": [
        "projection_dim = 128\n",
        "conv_filters = [32,64, projection_dim]\n",
        "num_patches = (image_size//2**(len(conv_filters))) **2\n",
        "num_heads = 3\n",
        "transformer_units = [projection_dim*2, projection_dim]\n",
        "transformer_layers = 4"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INFWmltNQnfo"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = L.Dense(units, activation = tf.nn.gelu)(x)\n",
        "        x = L.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODVje0tXvkbW"
      },
      "source": [
        "class CCTTokenizer(L.Layer):\n",
        "    def __init__(self):\n",
        "        super(CCTTokenizer, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection_dim = projection_dim\n",
        "        self.conv_model = keras.Sequential()\n",
        "        for i in conv_filters:\n",
        "            self.conv_model.add(\n",
        "                L.Conv2D(i,(3,3),activation='relu', padding='same')\n",
        "            )\n",
        "            self.conv_model.add(\n",
        "                L.MaxPool2D((2, 2), strides=(2, 2))\n",
        "            )\n",
        "\n",
        "        self.position_embedding = L.Embedding(\n",
        "            input_dim = self.num_patches, output_dim = self.projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, images):\n",
        "        outputs = self.conv_model(images)\n",
        "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
        "\n",
        "        reshaped = tf.reshape(\n",
        "            outputs,\n",
        "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n",
        "        )+self.position_embedding(positions)\n",
        "        return reshaped\n",
        "    \n",
        "    "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTyck_AZwcWr"
      },
      "source": [
        "def vision_transformer():\n",
        "    inputs = L.Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "    #conv_features= convolution_block(inputs)\n",
        "\n",
        "    # Encode patches.\n",
        "    encoded_patches = CCTTokenizer()(inputs)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        \n",
        "        # Layer normalization 1.\n",
        "        x1 = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "        \n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = L.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = projection_dim, dropout = 0.1\n",
        "        )(x1, x1)\n",
        "        \n",
        "        # Skip connection 1.\n",
        "        x2 = L.Add()([attention_output, encoded_patches])\n",
        "        \n",
        "        # Layer normalization 2.\n",
        "        x3 = L.LayerNormalization(epsilon = 1e-6)(x2)\n",
        "        \n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0.1)\n",
        "        \n",
        "        # Skip connection 2.\n",
        "        encoded_patches = L.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
        "    attention_weights = tf.nn.softmax(L.Dense(1)(representation), axis=1)\n",
        "    weighted_representation = tf.matmul(\n",
        "        attention_weights, representation, transpose_a=True\n",
        "    )\n",
        "    weighted_representation = tf.squeeze(weighted_representation, -2)\n",
        "\n",
        "    # Add MLP.\n",
        "    vit_features = L.Dense(128,activation='relu')(weighted_representation)\n",
        "    # Classify outputs.\n",
        "    out = L.Dense(2)(vit_features)\n",
        "    \n",
        "    # Create the model.\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fweaABGGxPdp"
      },
      "source": [
        "model = vision_transformer()\n",
        "model.compile(optimizer = Adam(learning_rate=0.001), \n",
        "              loss=MeanAbsoluteError())"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwJaaj6Ccmni",
        "outputId": "d54fba90-1229-4e6e-b3df-ee2e3cdcfa42"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cct_tokenizer_6 (CCTTokenizer)  (None, 784, 128)     193600      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_47 (LayerNo (None, 784, 128)     256         cct_tokenizer_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_21 (MultiH (None, 784, 128)     197888      layer_normalization_47[0][0]     \n",
            "                                                                 layer_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 784, 128)     0           multi_head_attention_21[0][0]    \n",
            "                                                                 cct_tokenizer_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_48 (LayerNo (None, 784, 128)     256         add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 784, 256)     33024       layer_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 784, 256)     0           dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 784, 128)     32896       dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 784, 128)     0           dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 784, 128)     0           dropout_43[0][0]                 \n",
            "                                                                 add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_49 (LayerNo (None, 784, 128)     256         add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_22 (MultiH (None, 784, 128)     197888      layer_normalization_49[0][0]     \n",
            "                                                                 layer_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 784, 128)     0           multi_head_attention_22[0][0]    \n",
            "                                                                 add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_50 (LayerNo (None, 784, 128)     256         add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 784, 256)     33024       layer_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 784, 256)     0           dense_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_56 (Dense)                (None, 784, 128)     32896       dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 784, 128)     0           dense_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 784, 128)     0           dropout_45[0][0]                 \n",
            "                                                                 add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_51 (LayerNo (None, 784, 128)     256         add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_23 (MultiH (None, 784, 128)     197888      layer_normalization_51[0][0]     \n",
            "                                                                 layer_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 784, 128)     0           multi_head_attention_23[0][0]    \n",
            "                                                                 add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_52 (LayerNo (None, 784, 128)     256         add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_57 (Dense)                (None, 784, 256)     33024       layer_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 784, 256)     0           dense_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 784, 128)     32896       dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 784, 128)     0           dense_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 784, 128)     0           dropout_47[0][0]                 \n",
            "                                                                 add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_53 (LayerNo (None, 784, 128)     256         add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_24 (MultiH (None, 784, 128)     197888      layer_normalization_53[0][0]     \n",
            "                                                                 layer_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 784, 128)     0           multi_head_attention_24[0][0]    \n",
            "                                                                 add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_54 (LayerNo (None, 784, 128)     256         add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_59 (Dense)                (None, 784, 256)     33024       layer_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 784, 256)     0           dense_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_60 (Dense)                (None, 784, 128)     32896       dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 784, 128)     0           dense_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 784, 128)     0           dropout_49[0][0]                 \n",
            "                                                                 add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_55 (LayerNo (None, 784, 128)     256         add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 784, 1)       129         layer_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.softmax_3 (TFOpLambda)    (None, 784, 1)       0           dense_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.linalg.matmul_3 (TFOpLambda) (None, 1, 128)       0           tf.nn.softmax_3[0][0]            \n",
            "                                                                 layer_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze_3 (TFOpLam (None, 128)          0           tf.linalg.matmul_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 128)          16512       tf.compat.v1.squeeze_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_63 (Dense)                (None, 2)            258         dense_62[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,268,035\n",
            "Trainable params: 1,268,035\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "6TwVPQqFbbB8",
        "outputId": "8b2aadf5-000b-4244-e506-426caae946fc"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    #model.load_weights(\"drive/MyDrive/CV/Model/CCT\")\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    r=model.fit(train_generator, validation_data=val_generator,\n",
        "                validation_steps=20,steps_per_epoch=211,epochs=100,callbacks=[callback])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "135/211 [==================>...........] - ETA: 39s - loss: 43.1963"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-8a1059a06930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     r=model.fit(train_generator, validation_data=val_generator,\n\u001b[0;32m----> 5\u001b[0;31m                 validation_steps=20,steps_per_epoch=211,epochs=100,callbacks=[callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv817pEGkWAt"
      },
      "source": [
        "model.save_weights(\"drive/MyDrive/CV/Model/vit\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PQ0WCpckr5x"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    ypred = model.predict(test_generator)\n",
        "ypred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XN7_GZkty6"
      },
      "source": [
        "df_test['x'] = ypred[:,0]\n",
        "df_test['y'] = ypred[:,1]\n",
        "if 'filename' in df_test.keys():\n",
        "    df_test=df_test.drop(columns=['filename'])\n",
        "df_test.head()\n",
        "df_test.to_csv('pred_CCT.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
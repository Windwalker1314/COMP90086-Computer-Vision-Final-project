{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_project_CCT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGgZzpDLsqOZ",
        "outputId": "03963cf3-c4fa-4617-8632-76ad2924b3f4"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36_-LhAXu3AT",
        "outputId": "c0b22de1-1cff-453e-8f70-6b3f8cfea0cd"
      },
      "source": [
        "!cp -av 'drive/MyDrive/CV/final_project/data_pure.zip' './' \n",
        "!unzip -u -q \"data_pure.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'drive/MyDrive/CV/final_project/data_pure.zip' -> './data_pure.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsIjWYHiu5zu"
      },
      "source": [
        "!pip install -U -q tensorflow-addons"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi1sad5XvAup",
        "outputId": "2bc951d5-aa13-44c6-e1b4-c5f1d564fcaa"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "seed = 1\n",
        "base_dir = './'\n",
        "image_size=224\n",
        "\n",
        "df = pd.read_csv(base_dir+\"data/train.csv\")\n",
        "df['filename'] = df.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "\n",
        "def prep_fn(img):\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    #img = (img - 0.5) * 2\n",
        "    return img\n",
        "\n",
        "data_gen_args = dict(preprocessing_function=prep_fn,\n",
        "                     width_shift_range=0.05,\n",
        "                     height_shift_range=0.2,\n",
        "                     zoom_range=0.05,\n",
        "                     rotation_range=5,\n",
        "                     horizontal_flip=False,\n",
        "                     vertical_flip=False,\n",
        "                     validation_split=0.1)\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=prep_fn,validation_split=0.1)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                    directory=base_dir+'data/train/',\n",
        "                                                    x_col='filename',\n",
        "                                                    y_col=['x','y'],\n",
        "                                                    subset=\"training\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    seed=seed,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='raw',\n",
        "                                                    target_size=(224,224))\n",
        "val_generator = val_datagen.flow_from_dataframe(dataframe=df,\n",
        "                                                directory=base_dir+'data/train/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                subset=\"validation\",\n",
        "                                                batch_size = 32,\n",
        "                                                seed=seed,\n",
        "                                                shuffle=True,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(224,224))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6750 validated image filenames.\n",
            "Found 750 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az3c9Aq5lmqv",
        "outputId": "3bbae570-1f5e-4b27-ade1-f94ba4048e31"
      },
      "source": [
        "df_test = pd.read_csv(\"data/imagenames.csv\")\n",
        "df_test['filename'] = df_test.apply(lambda row: row['id']+'.jpg',axis=1)\n",
        "df_test['x']=0\n",
        "df_test['y']=0\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n",
        "                                                directory=base_dir+'data/test/',\n",
        "                                                x_col='filename',\n",
        "                                                y_col=['x','y'],\n",
        "                                                batch_size = 32,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='raw',\n",
        "                                                target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE4zHMGrvSvm"
      },
      "source": [
        "projection_dim = 128\n",
        "conv_filters = [32,64, projection_dim]\n",
        "num_patches = (image_size//2**(len(conv_filters))) **2\n",
        "num_heads = 3"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INFWmltNQnfo"
      },
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = L.Dense(units, activation = tf.nn.gelu)(x)\n",
        "        x = L.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODVje0tXvkbW"
      },
      "source": [
        "class CCTTokenizer(L.Layer):\n",
        "    def __init__(self):\n",
        "        super(CCTTokenizer, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection_dim = projection_dim\n",
        "\n",
        "        \"\"\"\n",
        "        self.conv_model = tf.keras.Model(inputs = Xception_model.get_layer(\"block1_conv1\").input, \\\n",
        "                                         outputs = Xception_model.output)\n",
        "        for layer in self.conv_model.layers:\n",
        "            layer.trainable = False\n",
        "        \"\"\"\n",
        "        self.conv_model = keras.Sequential()\n",
        "        for i in conv_filters:\n",
        "            self.conv_model.add(\n",
        "                L.Conv2D(i,(3,3),activation='relu', padding='same')\n",
        "            )\n",
        "            self.conv_model.add(\n",
        "                L.MaxPool2D((2, 2), strides=(2, 2))\n",
        "            )\n",
        "        \n",
        "        self.position_embedding = L.Embedding(\n",
        "            input_dim = self.num_patches, output_dim = self.projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, images):\n",
        "        outputs = self.conv_model(images)\n",
        "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
        "        #print(outputs.shape)\n",
        "        reshaped = tf.reshape(\n",
        "            outputs,\n",
        "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[-1]),\n",
        "        )+ self.position_embedding(positions)\n",
        "        #print(tf.shape(reshaped), self.position_embedding(positions).shape)\n",
        "        return reshaped"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTyck_AZwcWr"
      },
      "source": [
        "def attention_block(inputs, key_dim, mlp_dim,dropout=0):\n",
        "    x = L.LayerNormalization(epsilon = 1e-6)(inputs)\n",
        "    attention_output = L.MultiHeadAttention(\n",
        "        num_heads = num_heads, key_dim = key_dim, dropout = dropout\n",
        "    )(x, x)\n",
        "    if(inputs.shape[-1]==key_dim):\n",
        "        x = L.Add()([inputs,attention_output])\n",
        "    skip = x\n",
        "    x = L.LayerNormalization(epsilon = 1e-6)(x)\n",
        "    x = mlp(x, hidden_units = mlp_dim, dropout_rate = dropout)\n",
        "    if(skip.shape[-1]==x.shape[-1]):\n",
        "        x = L.Add()([skip,x])\n",
        "    return x\n",
        "\n",
        "def vision_transformer():\n",
        "    inputs = L.Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "    #conv_features= convolution_block(inputs)\n",
        "\n",
        "    # Encode patches.\n",
        "    x = CCTTokenizer()(inputs)\n",
        "\n",
        "    for i in range(4):\n",
        "        x = attention_block(x, 128, [256,128], 0)\n",
        "\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    x = L.LayerNormalization(epsilon = 1e-6)(x)\n",
        "\n",
        "    x = x[:,0,:]\n",
        "    #x = L.GlobalAveragePooling1D()(x) \n",
        "\n",
        "    x = L.Dense(64,activation='relu')(x)\n",
        "    out = L.Dense(2)(x)\n",
        "    \n",
        "    # Create the model.\n",
        "    model = tf.keras.Model(inputs = inputs, outputs = out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fweaABGGxPdp"
      },
      "source": [
        "model = vision_transformer()\n",
        "model.compile(optimizer = Adam(learning_rate=0.001), \n",
        "              loss=MeanAbsoluteError())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwJaaj6Ccmni",
        "outputId": "a07aa88c-355d-43ae-df66-884f579b0f72"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cct_tokenizer_11 (CCTTokenizer) (None, 784, 128)     193600      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_99 (LayerNo (None, 784, 128)     256         cct_tokenizer_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_44 (MultiH (None, 784, 128)     197888      layer_normalization_99[0][0]     \n",
            "                                                                 layer_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 784, 128)     0           cct_tokenizer_11[0][0]           \n",
            "                                                                 multi_head_attention_44[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_100 (LayerN (None, 784, 128)     256         add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_108 (Dense)               (None, 784, 256)     33024       layer_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 784, 256)     0           dense_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_109 (Dense)               (None, 784, 128)     32896       dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 784, 128)     0           dense_109[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_81 (Add)                    (None, 784, 128)     0           add_80[0][0]                     \n",
            "                                                                 dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_101 (LayerN (None, 784, 128)     256         add_81[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_45 (MultiH (None, 784, 128)     197888      layer_normalization_101[0][0]    \n",
            "                                                                 layer_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_82 (Add)                    (None, 784, 128)     0           add_81[0][0]                     \n",
            "                                                                 multi_head_attention_45[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_102 (LayerN (None, 784, 128)     256         add_82[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_110 (Dense)               (None, 784, 256)     33024       layer_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 784, 256)     0           dense_110[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_111 (Dense)               (None, 784, 128)     32896       dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 784, 128)     0           dense_111[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_83 (Add)                    (None, 784, 128)     0           add_82[0][0]                     \n",
            "                                                                 dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_103 (LayerN (None, 784, 128)     256         add_83[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_46 (MultiH (None, 784, 128)     197888      layer_normalization_103[0][0]    \n",
            "                                                                 layer_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_84 (Add)                    (None, 784, 128)     0           add_83[0][0]                     \n",
            "                                                                 multi_head_attention_46[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_104 (LayerN (None, 784, 128)     256         add_84[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_112 (Dense)               (None, 784, 256)     33024       layer_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 784, 256)     0           dense_112[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_113 (Dense)               (None, 784, 128)     32896       dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 784, 128)     0           dense_113[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_85 (Add)                    (None, 784, 128)     0           add_84[0][0]                     \n",
            "                                                                 dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_105 (LayerN (None, 784, 128)     256         add_85[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_47 (MultiH (None, 784, 128)     197888      layer_normalization_105[0][0]    \n",
            "                                                                 layer_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_86 (Add)                    (None, 784, 128)     0           add_85[0][0]                     \n",
            "                                                                 multi_head_attention_47[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_106 (LayerN (None, 784, 128)     256         add_86[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_114 (Dense)               (None, 784, 256)     33024       layer_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 784, 256)     0           dense_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_115 (Dense)               (None, 784, 128)     32896       dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 784, 128)     0           dense_115[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_87 (Add)                    (None, 784, 128)     0           add_86[0][0]                     \n",
            "                                                                 dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_107 (LayerN (None, 784, 128)     256         add_87[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 128)          0           layer_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_116 (Dense)               (None, 64)           8256        tf.__operators__.getitem_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_117 (Dense)               (None, 2)            130         dense_116[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,259,522\n",
            "Trainable params: 1,259,522\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "6TwVPQqFbbB8",
        "outputId": "29fc7407-cf00-4ce1-8744-9b6f49936b7e"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model.load_weights(\"drive/MyDrive/CV/Model/CCT\")\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    r=model.fit(train_generator, validation_data=val_generator,\n",
        "                validation_steps=20,steps_per_epoch=211,epochs=100,callbacks=[callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "211/211 [==============================] - 129s 528ms/step - loss: 4.7739 - val_loss: 13.5229\n",
            "Epoch 2/100\n",
            "211/211 [==============================] - 111s 526ms/step - loss: 4.5869 - val_loss: 9.1477\n",
            "Epoch 3/100\n",
            "211/211 [==============================] - 111s 524ms/step - loss: 3.8648 - val_loss: 8.8730\n",
            "Epoch 4/100\n",
            "211/211 [==============================] - 112s 529ms/step - loss: 3.6828 - val_loss: 9.3367\n",
            "Epoch 5/100\n",
            "211/211 [==============================] - 111s 524ms/step - loss: 3.6581 - val_loss: 10.4589\n",
            "Epoch 6/100\n",
            " 18/211 [=>............................] - ETA: 1:37 - loss: 3.8390"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3c286b036407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     r=model.fit(train_generator, validation_data=val_generator,\n\u001b[0;32m----> 5\u001b[0;31m                 validation_steps=20,steps_per_epoch=211,epochs=100,callbacks=[callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv817pEGkWAt"
      },
      "source": [
        "model.save_weights(\"drive/MyDrive/CV/Model/CCT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PQ0WCpckr5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80efce6e-6b39-43d6-ea5c-cc47109b917f"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    ypred = model.predict(test_generator)\n",
        "ypred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XN7_GZkty6"
      },
      "source": [
        "df_test['x'] = ypred[:,0]\n",
        "df_test['y'] = ypred[:,1]\n",
        "if 'filename' in df_test.keys():\n",
        "    df_test=df_test.drop(columns=['filename'])\n",
        "df_test.head()\n",
        "df_test.to_csv('pred_CCT.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}